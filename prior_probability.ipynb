{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "prior_probability.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/kapsdeep/FER/blob/master/prior_probability.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "p5ULE4qkA9-k",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Code Flow**\n",
        "\n",
        "1.   Use CK+ database with expression label and AU labels - *#309 images*\n",
        "2.   Process the images to obtain frontal and uniform eye distance faces - *using facemask for test*\n",
        "3.   Scale the obtained images to agreed resolution without distorting aspect-ratio\n",
        "\n",
        "---\n",
        "\n",
        "Alternating Optimization \n",
        "\n",
        "4.   Use Expression-AU relationship table#2 to initialize missing AU labels as 1 or 0\n",
        "5.   Extract features and textures from processed images using local binary pattern - *sklearn module*\n",
        "6.   Reduce dimensionality of the data using PCA/LDA/Adaboost/Gentleboost - *planned in next iteration*\n",
        "7.   Train SVM classifier with linear kernel per Eq#21 - *L-BGFS planned in next iteration*\n",
        "8.   After converging step#7, fix W using optimized values\n",
        "9.   Start training again using Eq#22\n",
        "10.   Find best AU config for each sample by Eq#20\n",
        "11.   If Eq#20 minimized then replace AU config else don't\n",
        "12.   Repeat step9-11 until all samples are best per Eq#20\n",
        "13.   Repeat from step#7\n",
        "\n",
        "Part2 of alternating optimization algo\n",
        "\n",
        "1. For each training sample compute Eq#22 using the loss equations but how to estimate penalty factors ? using gridsearchcv ?\n",
        "example for S005_001_00000011.png-4,9,10,17 we will compute eq#22 for AU4 classifier - same to be repeated for 9,10,17\n",
        "1a. but how to minimize Eq#22 once derived using the probabilty losses (iterate 2powerm)\n",
        "1b. how to estimate penalty factors from specified range (ask q to author)\n",
        "1c. M in Eq#22 is total #AU classifier trained jointly or #AUs identified/estimated in a sample ?\n",
        "1d. considering Eq#7 \"Expr indp joint prob\" calculation, where to look for \"Pi1j1 - the estimated joint probability of co-occurrence\" ? use derivation on dataset as stated below eq#7 for joint & single ?\n",
        "1e. how to implement eq#12 ?\n",
        "1f. any best practices while calculating estimated probabilities on training dataset to be used ?\n",
        "2. Repeat step#1 for all training samples but how to minimize eq#22 ?\n",
        "3. assuming best AU config for each sample using eq#22, how to minimize eq#20 ? how to estimate penalty factors ?\n",
        "4. compare eq#20 o/p for each sample and select the minimum one \n",
        "5. update AU config of step#4 and leave the rest\n",
        "6. repeat step2-5 until no further reduction in eq#20 o/p for samples\n",
        "7. repeat part#1=>steps#1-6 until no convergence\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "ZZYK6XjxMjIT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def download_dataset_to_collab(dataset):\n",
        "  '''\n",
        "  Google Drive is a tag-based (also called semantic) file system, which, for example, allows a file to be in several places at the same time \n",
        "  (just by adding IDs of folders to the file's parents property)\n",
        "  Hence to get the file/folder ID, navigate to the folder using browser & note the ID from URL \n",
        "  Ex: https://drive.google.com/drive/folders/1mZVxppM8dHFcoKdc9Vu9vS-n_GGnpCkO\n",
        "  '''\n",
        "  #Code to download files from google drive to collab using Pydrive\n",
        "\n",
        "  !pip install -U -q PyDrive\n",
        "\n",
        "  from pydrive.auth import GoogleAuth\n",
        "  from pydrive.drive import GoogleDrive\n",
        "  from google.colab import auth\n",
        "  from oauth2client.client import GoogleCredentials\n",
        "  import time\n",
        "\n",
        "  # 1. Authenticate and create the PyDrive client.\n",
        "  auth.authenticate_user()\n",
        "  gauth = GoogleAuth()\n",
        "  gauth.credentials = GoogleCredentials.get_application_default()\n",
        "  drive = GoogleDrive(gauth)\n",
        "\n",
        "  # Auto-iterate through all files in the folder ID.\n",
        "  start = time.time()\n",
        "  for key, value in dataset.items():\n",
        "    print(\"Initiating files copy from {} ...\".format(key))\n",
        "    if('dir' in key):\n",
        "      file_list = drive.ListFile({'q': \"'{}' in parents and trashed=false\".format(value)}).GetList()      #file_list = drive.ListFile({'q': \"'1czmCOb4w0LiWetvQyhIxi6gGvJuAYb5F' in parents and trashed=false\"}).GetList()\n",
        "      for file1 in file_list:      \n",
        "        file6 = drive.CreateFile({'id': file1['id']}) # Initialize GoogleDriveFile instance with file id.\n",
        "        file6.GetContentFile(file1['title'])          # Download file as file1['title']\n",
        "    else:\n",
        "        fileId = drive.CreateFile({'id': value})\n",
        "        print(type(value))\n",
        "        print(fileId)\n",
        "        print('title: %s, mimeType: %s' % (fileId['title'], fileId['mimeType']))\n",
        "        fileId.GetContentFile(fileId['title'])\n",
        "    print(\"Completed files copy from {}.\".format(key))\n",
        "\n",
        "  end = time.time()                                                                \n",
        "  return 'time taken:'+ str(end-start) +'seconds'\n",
        "\n",
        "dataset = {\n",
        "          #'<file/folder_name>':'<gdrive_folder_id>'\n",
        "          'dir1':'1ofsIjkg47c0GtFiTCEnyMN_QKrxQG93q',\n",
        "          'dir2':'1_ipqV9ISrHTVDxJS3WX_VKPJQ4P0JZgP',\n",
        "          'file1':'1PpeI6Rly8NaSMjHbnrP259sWo0Xzxt1J',\n",
        "          'file2':'1RI-ZTABI0-zfeC5RyM3io5BXqbflLoHV'\n",
        "          }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Fz-la5nUORYS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d6c172f9-b6ae-4e7b-8948-c05abdc03620"
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "import itertools, time\n",
        "!pip install xlrd\n",
        "download_dataset_to_collab(dataset)\n",
        "!mkdir -p datalab/img\n",
        "!mv *.png datalab/img\n",
        "tick = time.time()\n",
        "!pwd\n",
        "!ls -l\n",
        "!ls datalab/img | wc -l\n",
        "tock = time.time()\n",
        "print(tock-tick)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: xlrd in /usr/local/lib/python2.7/dist-packages (1.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "G7tF1htUc0no",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#http://scikit-image.org/docs/dev/api/skimage.transform.html#skimage.transform.downscale_local_mean\n",
        "from skimage.transform import resize, pyramid_reduce\n",
        "from skimage.io import imread, imsave\n",
        "import numpy as np\n",
        "\n",
        "#https://stackoverflow.com/questions/44650888/resize-an-image-without-distortion-opencv\n",
        "def scale_img_to_sqaure(img_abs_path, square_size):\n",
        "\n",
        "  image = np.asarray(imread(img_abs_path))/255.0\n",
        "  file_name = img_abs_path.split('/')[-1]\n",
        "\n",
        "  height, width = image.shape    \n",
        "  if(height > width):\n",
        "    differ = height\n",
        "  else:\n",
        "    differ = width\n",
        "  differ += 4\n",
        "\n",
        "  # square filler\n",
        "  mask = np.zeros((differ, differ), dtype = \"float64\")\n",
        "\n",
        "  x_pos = int((differ - width) / 2.0)\n",
        "  y_pos = int((differ - height) / 2.0)\n",
        "\n",
        "  # center image inside the square\n",
        "  mask[y_pos: y_pos + height, x_pos: x_pos + width] = image[0: height, 0: width]\n",
        "\n",
        "  # downscale if needed\n",
        "  if differ / square_size > 1:\n",
        "    mask = pyramid_reduce(mask, differ / square_size)\n",
        "  else:\n",
        "    mask = cv2.resize(mask, (square_size, square_size), interpolation = cv2.INTER_AREA)\n",
        "  imsave(file_name,mask)\n",
        "  return mask  \n",
        "\n",
        "# sq = scale_img_to_sqaure('/content/datalab/img/S037_003_00000022.png',96)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2L6tR5ELcE78",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "2f42701c-2d99-4eb4-cf59-cdc26768a469"
      },
      "cell_type": "code",
      "source": [
        "#https://www.bytefish.de/blog/local_binary_patterns/\n",
        "#http://scikit-image.org/docs/dev/auto_examples/features_detection/plot_local_binary_pattern.html\n",
        "from skimage.transform import rotate\n",
        "from skimage.feature import local_binary_pattern\n",
        "from skimage import data\n",
        "from skimage.color import label2rgb\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "METHOD = 'uniform'\n",
        "plt.rcParams['font.size'] = 9\n",
        "\n",
        "# settings for LBP\n",
        "radius = 3\n",
        "n_points = 8 * radius\n",
        "\n",
        "\n",
        "def overlay_labels(image, lbp, labels):\n",
        "    mask = np.logical_or.reduce([lbp == each for each in labels])\n",
        "    return label2rgb(mask, image=image, bg_label=0, alpha=0.5)\n",
        "\n",
        "\n",
        "def highlight_bars(bars, indexes):\n",
        "    for i in indexes:\n",
        "        bars[i].set_facecolor('r')\n",
        "\n",
        "\n",
        "image = data.load('/content/datalab/img/S052_004_00000033.png')\n",
        "print(image[200,250])\n",
        "lbp = local_binary_pattern(image, n_points, radius, METHOD)\n",
        "print(lbp[200,250])\n",
        "\n",
        "def hist(ax, lbp):\n",
        "    n_bins = int(lbp.max() + 1)\n",
        "    return ax.hist(lbp.ravel(), normed=True, bins=n_bins, range=(0, n_bins),\n",
        "                   facecolor='0.5')\n",
        "\n",
        "\n",
        "# plot histograms of LBP of textures\n",
        "fig, (ax_img, ax_hist) = plt.subplots(nrows=2, ncols=3, figsize=(9, 6))\n",
        "plt.gray()\n",
        "\n",
        "titles = ('edge', 'flat', 'corner')\n",
        "w = width = radius - 1\n",
        "edge_labels = range(n_points // 2 - w, n_points // 2 + w + 1)\n",
        "flat_labels = list(range(0, w + 1)) + list(range(n_points - w, n_points + 2))\n",
        "i_14 = n_points // 4            # 1/4th of the histogram\n",
        "i_34 = 3 * (n_points // 4)      # 3/4th of the histogram\n",
        "corner_labels = (list(range(i_14 - w, i_14 + w + 1)) +\n",
        "                 list(range(i_34 - w, i_34 + w + 1)))\n",
        "\n",
        "label_sets = (edge_labels, flat_labels, corner_labels)\n",
        "\n",
        "for ax, labels in zip(ax_img, label_sets):\n",
        "    ax.imshow(overlay_labels(image, lbp, labels))\n",
        "\n",
        "for ax, labels, name in zip(ax_hist, label_sets, titles):\n",
        "    counts, _, bars = hist(ax, lbp)\n",
        "    highlight_bars(bars, labels)\n",
        "    ax.set_ylim(ymax=np.max(counts[:-1]))\n",
        "    ax.set_xlim(xmax=n_points + 2)\n",
        "    ax.set_title(name)\n",
        "\n",
        "ax_hist[0].set_ylabel('Percentage')\n",
        "for ax in ax_img:\n",
        "    ax.axis('off')\n",
        "#print(list(W))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "247\n",
            "15.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAicAAAFXCAYAAAB5mu6BAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIxajAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f7d22095790>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "_Vu1sQ_cE--H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv \n",
        "from skimage import data\n",
        "from skimage.io import imsave, imshow\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn import svm, metrics, linear_model\n",
        "\n",
        "def get_au_label(csvfile, imgfile):\n",
        "  \n",
        "  with open(csvfile, 'r') as f:\n",
        "    r = csv.reader(f, delimiter=' ', quotechar='|')\n",
        "    for row in r:\n",
        "      if imgfile in row[0]:\n",
        "        name,value=row[0].split(',')\n",
        "        return int(value)\n",
        "\n",
        "def get_au_label1(img,au):\n",
        "  dataset = pd.ExcelFile('/content/Probabilities.xlsx')\n",
        "  probabilities = dataset.parse(0)\n",
        "  temp = probabilities.iloc[:,[0,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21]]\n",
        "  return int(temp[(temp['File']==img)][au].values[0])\n",
        "\n",
        "def get_expr_label(img):\n",
        "  dataset = pd.ExcelFile('/content/Probabilities.xlsx')\n",
        "  probabilities = dataset.parse(0)\n",
        "  temp = probabilities.iloc[:,[0,3]]\n",
        "  return str(temp[(temp['File']==img)]['Expressions'].values[0])\n",
        "\n",
        "def get_lbp(img_path):\n",
        "\n",
        "  # settings for LBP\n",
        "  radius = 3\n",
        "  n_points = 8 * radius\n",
        "  METHOD = 'uniform'\n",
        "\n",
        "  image = data.load(img_path)\n",
        "  return local_binary_pattern(image, n_points, radius, METHOD)\n",
        "\n",
        "def img_to_vector(path,au):\n",
        "  \n",
        "  X_train = np.ndarray(shape=(len(os.listdir(path)), 101, 101), dtype=np.float64)\n",
        "  Y_train = np.ndarray(shape=len(os.listdir(path)),dtype=np.float16)\n",
        "  X_expr = []\n",
        "  i=0\n",
        "  for img in os.listdir(path):\n",
        "    s,t = img.split('.')  \n",
        "    Y_train[i] = get_au_label1(s,au)\n",
        "    X_expr.append(get_expr_label(s))\n",
        "    sq_img = scale_img_to_sqaure(path+str(img), 96)\n",
        "    X_train[i] = get_lbp('/content/'+str(img))\n",
        "    i += 1\n",
        "  return X_train,Y_train, X_expr\n",
        "\n",
        "def train_svc(X, y, x_test):  \n",
        "  clf = svm.LinearSVC(random_state=0)\n",
        "  clf.fit(X, y)  \n",
        "  svm.LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True, intercept_scaling=1, loss='hinge', max_iter=1000, multi_class='ovr', penalty='l2', random_state=0, tol=0.0001, verbose=1)\n",
        "  return clf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iF3wuWo4RAAu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def eq21_training(y_new, au_list):\n",
        "  i=0\n",
        "  W = np.ndarray(shape=(269, 10201), dtype=np.float64)\n",
        "  for au in au_list:\n",
        "    tick = time.time()\n",
        "    X_train, Y_train, X_expr = img_to_vector(\"/content/datalab/img/\",au)\n",
        "    Y_train = np.transpose(y_new[:,i])\n",
        "      \n",
        "    #Flatten the image vectors for SVM classifier \n",
        "    # - https://stackoverflow.com/questions/33162871/python-scikit-learn-svm-classifier-valueerror-found-array-with-dim-3-expected/35005672\n",
        "    # - https://www.kaggle.com/halien/simple-image-classifer-with-svm\n",
        "\n",
        "    X = X_train[0:269,:,:].reshape(269,-1)\n",
        "    y = Y_train[0:269,]\n",
        "    x_expr = X_expr[0:269]\n",
        "    x_test = X_train[270:,:,:].reshape(39,-1)\n",
        "    y_test = Y_train[270:,]\n",
        "\n",
        "    classifier = train_svc(X, y, x_test)\n",
        "    y_pred = classifier.predict(x_test)\n",
        "    confidence = classifier.decision_function(x_test)\n",
        "    #Coeeficients: (1, 10201)\n",
        "    W[i,:]=classifier.coef_\n",
        "    print(classifier.coef_)\n",
        "    print(W[i])\n",
        "    i += 1\n",
        "\n",
        "    print('*************AU{} Classifier*************'.format(au))\n",
        "    print('Pred: {}'.format(y_pred))\n",
        "    print('Test: {}'.format(y_test))\n",
        "    print('AU{} classifier co-eficients: {}'.format(au,classifier.coef_.shape))\n",
        "    print(\"Classification report for classifier {}, {}\".format(classifier, metrics.classification_report(y_test, y_pred)))\n",
        "    print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(y_test, y_pred))\n",
        "    tock = time.time()\n",
        "    print(tock-tick)\n",
        "  return W, X, x_expr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Nb31Ak6D-MXO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Express independent joint AU probability loss\n",
        "def eq8_loss(test_au_labels, positive_au_pairs, negative_au_pairs):\n",
        "  pt_loss = nt_loss = 0\n",
        "  '''positive_au_pairs = [i for i in positive_au_pairs if set(i)<=set(test_au_labels)]\n",
        "  negative_au_pairs = [i for i in negative_au_pairs if set(i)<=set(test_au_labels)]\n",
        "  print(positive_au_pairs)\n",
        "  print(negative_au_pairs)\n",
        "  for pt_pair in positive_au_pairs:\n",
        "    prob_i = get_prob_i(pt_pair[0])\n",
        "    prob_j = get_prob_i(pt_pair[1])\n",
        "    prob_ij = get_prob_ij(pt_pair)\n",
        "    print('prob_i'+str(prob_i))\n",
        "    print('prob_j'+str(prob_j))\n",
        "    print('prob_ij'+str(prob_ij))\n",
        "    pt_loss += max(0,(prob_i*prob_j - prob_ij)) + max(0,((1-prob_i)*prob_j - prob_ij)) + max(0,(prob_i*(1-prob_j) - prob_ij))'''\n",
        "  \n",
        "  ## Determine the positive pairs not occurring together\n",
        "  positive_au_pairs_not_present = list()\n",
        "  for i in test_au_labels:\n",
        "    for j in positive_au_pairs:\n",
        "      if i in j:\n",
        "        if not ((j[0] in test_au_labels) and (j[1] in test_au_labels)):\n",
        "          positive_au_pairs_not_present.append(j)\n",
        "  ######################################################\n",
        "  \n",
        "  for pt_pair in positive_au_pairs_not_present:\n",
        "    prob_i = get_prob_i(pt_pair[0])\n",
        "    prob_j = get_prob_i(pt_pair[1])\n",
        "    prob_ij = get_prob_ij(pt_pair)\n",
        "    pt_loss += max(0,(prob_i*prob_j - prob_ij)) + max(0,((1-prob_i)*prob_j - prob_ij)) + max(0,(prob_i*(1-prob_j) - prob_ij))\n",
        "    \n",
        "  negative_au_pairs = [i for i in negative_au_pairs if set(i)<=set(test_au_labels)]\n",
        "  for nt_pair in negative_au_pairs:\n",
        "      prob_i = get_prob_i(nt_pair[0])\n",
        "      prob_j = get_prob_i(nt_pair[1])\n",
        "      prob_ij = get_prob_ij(nt_pair)\n",
        "      nt_loss += max(0,(prob_ij - prob_i*prob_j)) + max(0,(prob_ij - (1-prob_i)*prob_j)) + max(0,(prob_ij - prob_i*(1-prob_j)))\n",
        "  return (pt_loss+nt_loss)\n",
        "\n",
        "#Expression dependent single AU probability loss - considering only 'primary'/'others' AU - SUMMATE over K\n",
        "def eq11_loss(test_au_labels, x_expr_label, primary_au, others_au):\n",
        "  loss=0\n",
        "  for pr_au in primary_au[x_expr_label]:\n",
        "    if pr_au not in test_au_labels:\n",
        "      prob_i_k = get_prob_i_under_k(pr_au, x_expr_label)\n",
        "      loss += max(0,(0.5 - prob_i_k))\n",
        "  for ot_au in others_au[x_expr_label]:\n",
        "    if ot_au in test_au_labels:\n",
        "      prob_i_k = get_prob_i_under_k(ot_au, x_expr_label)\n",
        "      loss += max(0,(prob_i_k - 0.5))    \n",
        "  return loss\n",
        "\n",
        "#Expression dependent single AU probability loss - calculating differences wrt table3\n",
        "def eq13_loss():\n",
        "  return loss\n",
        "\n",
        "#Expression dependent joint AU probability loss - (prob_primary > prob_secondary) & (prob_secondary > prob-others)\n",
        "def eq15_loss(test_au_labels, emotion_list, primary_secondary_au_pairs, secondary_others_au_pairs):\n",
        "  loss = 0\n",
        "  #Filter primary_secondary_au_pairs \n",
        "  for e in emotion_list:\n",
        "    primary_secondary_au_pairs[e] = [i for i in primary_secondary_au_pairs[e] if i[1] in test_au_labels and i[0] not in test_au_labels]\n",
        "    secondary_others_au_pairs[e] = [i for i in secondary_others_au_pairs[e] if i[1] in test_au_labels and i[0] not in test_au_labels]\n",
        "  for e in emotion_list:\n",
        "    for ps in primary_secondary_au_pairs[e]:\n",
        "      prob_prim = get_prob_i_under_k(ps[0], e)\n",
        "      prob_sec = get_prob_i_under_k(ps[1], e)\n",
        "      loss += max(0,(prob_sec - prob_prim))\n",
        "    for ps in secondary_others_au_pairs[e]:\n",
        "      prob_sec = get_prob_i_under_k(ps[0], e)\n",
        "      prob_oth = get_prob_i_under_k(ps[1], e)        \n",
        "      loss += max(0,(prob_oth - prob_sec))\n",
        "  return loss\n",
        "\n",
        "#Expression dependent joint AU probability loss - positive correlation per table4 - SUMMATE over K\n",
        "def eq19_loss(test_au_labels, emotion_list, emfacs):\n",
        "  loss = 0\n",
        "  #Filter emfacs\n",
        "  '''for e in emotion_list:\n",
        "    emfacs[e] = [i for i in emfacs[e] if set(i)<=set(test_au_labels)]'''\n",
        "  #Filter emfacs\n",
        "  emfacs_pairs_not_present = defaultdict(list)\n",
        "  for e in emotion_list:\n",
        "    for i in test_au_labels:\n",
        "      for j in emfacs[e]:\n",
        "        if i in j:\n",
        "          if not ((j[0] in test_au_labels) and (j[1] in test_au_labels)):\n",
        "            emfacs_pairs_not_present[e].append(j)\n",
        "  \n",
        "  emfacs_pairs_not_present = dict(emfacs_pairs_not_present)\n",
        "  for e in emotion_list:\n",
        "    if e in emfacs_pairs_not_present:\n",
        "      for ps in emfacs_pairs_not_present[e]:\n",
        "        prob_i_k = get_prob_i_under_k(ps[0], e)\n",
        "        prob_j_k = get_prob_i_under_k(ps[1], e)\n",
        "        prob_ij_k = get_prob_ij_under_k(ps, e)\n",
        "        loss += max(0,(prob_i_k*prob_j_k - prob_ij_k)) + max(0,((1-prob_i_k)*prob_j_k - prob_ij_k)) + max(0,(prob_i_k*(1-prob_j_k) - prob_ij_k))\n",
        "    else:\n",
        "      pass\n",
        "  return loss\n",
        "\n",
        "#plan to use code to estimate optimum value for each lambda but for getting ahead assuming all to be 10 from range {10, 10^2, 10^3, 10^4}  \n",
        "def lambda_optimization():  \n",
        "  lambd_eq8=lambd_eq13=lambd_eq19=lambd_eq15 = 10\n",
        "  lambda_eq11 = 100\n",
        "  return lambd_eq8, lambda_eq11, lambd_eq13, lambd_eq19, lambd_eq15\n",
        "\n",
        "#Calculate hinge loss\n",
        "def hinge_loss(y, x, w):\n",
        "  return max(0,(1 - (y*(np.dot(np.transpose(w),x)))))\n",
        "\n",
        "#Calculate classification loss\n",
        "def classification_loss(au_config, x, W):\n",
        "  clf_loss = 0\n",
        "  for m in range(len(au_config)):\n",
        "    w = W[m,:]\n",
        "    y = au_config[m]\n",
        "    clf_loss += hinge_loss(y, w, x)\n",
        "  return clf_loss\n",
        "\n",
        "def eq22_loss(test_au_config, x, W, x_expr_label, au_list, primary_au, secondary_au, others_au, positive_au_pairs, negative_au_pairs, emotion_list):  \n",
        "\n",
        "  M = len(au_list)\n",
        "  au_test_config_arr = np.array(list(itertools.product([0, 1], repeat=M)))\n",
        "  lambd_eq8, lambda_eq11, lambd_eq13, lambd_eq19, lambd_eq15 = lambda_optimization()\n",
        "  primary_secondary_au_pairs = pairs_from_dictionaries(primary_au, secondary_au, emotion_list)\n",
        "  secondary_others_au_pairs = pairs_from_dictionaries(secondary_au, others_au, emotion_list)\n",
        "  test_au_labels = au_label_list(au_list, test_au_config)\n",
        "  \n",
        "  total_loss = Loss_eq8 = Loss_eq11 = Loss_eq13 = Loss_eq15 = Loss_eq19 = 0\n",
        "\n",
        "  #Classification loss calculations\n",
        "  clf_loss = classification_loss(test_au_config, x, W)\n",
        "\n",
        "  \n",
        "  #Loss_eq8\n",
        "  Loss_eq8 = lambd_eq8 * eq8_loss(test_au_labels, positive_au_pairs, negative_au_pairs)\n",
        "\n",
        "  #Loss_eq11      \n",
        "  Loss_eq11 = lambda_eq11 * eq11_loss(test_au_labels, x_expr_label, primary_au, others_au)\n",
        "\n",
        "  #Loss_eq15\n",
        "  Loss_eq15 = lambd_eq15 * eq15_loss(test_au_labels, emotion_list, primary_secondary_au_pairs, secondary_others_au_pairs)\n",
        "\n",
        "  #Loss_eq19\n",
        "  Loss_eq19 = lambd_eq19 * eq19_loss(test_au_labels, emotion_list, emfacs_pairs)\n",
        "\n",
        "  print('clf_loss:{} eq8_loss:{} eq11_loss:{} eq13_loss:{} eq15_loss:{} eq19_loss:{}'.format(clf_loss,Loss_eq8,Loss_eq11,Loss_eq13,Loss_eq15,Loss_eq19))\n",
        "  total_loss = (clf_loss + Loss_eq8 + Loss_eq11 + Loss_eq13 + Loss_eq15 + Loss_eq19)/M\n",
        "  return total_loss\n",
        "\n",
        "def get_eq22_best_AU_config(au_test_config_arr, x, sample_no, x_expr_label, W, au_list, primary_au, secondary_au, others_au, positive_au_pairs, negative_au_pairs, emotion_list):\n",
        "  min_loss = None\n",
        "  y_eq22_best = au_test_config_arr[0]\n",
        "  for test_au_config in au_test_config_arr:\n",
        "    tick=time.time()\n",
        "    x_loss = eq22_loss(test_au_config, x, W, x_expr_label, au_list, primary_au, secondary_au, others_au, positive_au_pairs, negative_au_pairs, emotion_list)\n",
        "    if min_loss == None:\n",
        "      min_loss = x_loss  \n",
        "    if x_loss < min_loss:\n",
        "      min_loss = x_loss\n",
        "      y_eq22_best = test_au_config\n",
        "    tock=time.time()\n",
        "    print('sample: {} x_loss: {} for {} min_loss: {} for {} under {}s'.format(sample_no, x_loss,test_au_config,min_loss,y_eq22_best,(tock-tick)))\n",
        "  return y_eq22_best\n",
        "\n",
        "def compute_eq20_obj(best_au_config, X, W, x_expr_label, y_new, au_list, primary_au, secondary_au, others_au, positive_au_pairs, negative_au_pairs, emotion_list):\n",
        "\n",
        "  M = len(au_list)\n",
        "  lambd_eq8, lambda_eq11, lambd_eq13, lambd_eq19, lambd_eq15 = lambda_optimization()\n",
        "  primary_secondary_au_pairs = pairs_from_dictionaries(primary_au, secondary_au, emotion_list)\n",
        "  secondary_others_au_pairs = pairs_from_dictionaries(secondary_au, others_au, emotion_list)\n",
        "  test_au_labels = au_label_list(au_list, best_au_config)\n",
        "  \n",
        "  main_obj = Loss_eq8 = Loss_eq11 = Loss_eq13 = Loss_eq15 = Loss_eq19 = 0\n",
        "\n",
        "  #Classification loss calculations\n",
        "  for sample in range(y_new.shape[0]):\n",
        "    x=X[sample]\n",
        "    clf_loss = classification_loss(np.transpose(y_new[sample,:]), x, W)\n",
        " \n",
        "  #Loss_eq8\n",
        "  Loss_eq8 = lambd_eq8 * eq8_loss(test_au_labels, positive_au_pairs, negative_au_pairs)\n",
        "\n",
        "  #Loss_eq11      \n",
        "  Loss_eq11 = lambda_eq11 * eq11_loss(test_au_labels, x_expr_label, primary_au, others_au)\n",
        "\n",
        "  #Loss_eq15\n",
        "  Loss_eq15 = lambd_eq15 * eq15_loss(test_au_labels, emotion_list, primary_secondary_au_pairs, secondary_others_au_pairs)\n",
        "\n",
        "  #Loss_eq19\n",
        "  Loss_eq19 = lambd_eq19 * eq19_loss(test_au_labels, emotion_list, emfacs_pairs)\n",
        "\n",
        "  main_obj = (clf_loss + Loss_eq8 + Loss_eq11 + Loss_eq13 + Loss_eq15 + Loss_eq19)/M\n",
        "  return main_obj"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OdDdRmHpLxva",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Convert binary AU config array to AU label array\n",
        "def au_label_list(au_list, au_config):\n",
        "  M = len(au_list)\n",
        "  au_labels=[]\n",
        "  for m in range(M):\n",
        "    if au_config[m] == 1:\n",
        "      au_labels.append(au_list[m])\n",
        "  return au_labels\n",
        "\n",
        "#Get all pairs of items from dictionaries in specified order\n",
        "def pairs_from_dictionaries(dict1, dict2, emotion_list):\n",
        "  pairs_dict1_dict2 = {}\n",
        "  for e in emotion_list:\n",
        "    list_of_pairs = []\n",
        "    for x in dict1[e]:\n",
        "      for y in dict2[e]:\n",
        "        list_of_pairs.append([x,y])\n",
        "    pairs_dict1_dict2[e] = list_of_pairs\n",
        "  return pairs_dict1_dict2\n",
        "  \n",
        "#Get expression independent marginal AU probability that is calculated from dataset\n",
        "def get_prob_i(au):\n",
        "  dataset = pd.ExcelFile('/content/Probabilities.xlsx')\n",
        "  probabilities = dataset.parse(0)\n",
        "  probabilities = probabilities.iloc[:,4:]\n",
        "  n_array = probabilities.values\n",
        "\n",
        "  indi_prob_dict = defaultdict()\n",
        "  columns = list(probabilities.columns)\n",
        "  individualProbabilities = np.sum(n_array,axis=0)/309.0\n",
        "  for index,value in enumerate(columns):\n",
        "      indi_prob_dict[value] = individualProbabilities[index]\n",
        "\n",
        "  return indi_prob_dict[au]\n",
        "\n",
        "#Get expression independent marginal AU probability that is calculated from dataset\n",
        "def get_prob_ij(au_pair):\n",
        "  dataset = pd.ExcelFile('/content/Probabilities.xlsx')\n",
        "  probabilities = dataset.parse(0)\n",
        "  probabilities = probabilities.iloc[:,4:]\n",
        "  n_array = probabilities.values\n",
        "  \n",
        "  joint_prob_dict_11 = defaultdict()\n",
        "  columns = list(probabilities.columns)\n",
        "  for cols in itertools.combinations(range(18),2):\n",
        "      temp = n_array[:,cols]\n",
        "      (x,y) = columns[cols[0]],columns[cols[1]]\n",
        "      #print(temp),.\n",
        "      temp_11 = temp[ (temp[:,0]==1) & (temp[:,1]==1)]\n",
        "      joint_prob_dict_11[(x,y)] = temp_11.shape[0]/309.0\n",
        "  return joint_prob_dict_11[au_pair]\n",
        "\n",
        "#Get expression dependent marginal AU probability that is calculated from dataset\n",
        "def get_prob_i_under_k(au, emotion):\n",
        "  dataset = pd.ExcelFile('/content/Probabilities.xlsx')\n",
        "  probabilities = dataset.parse(0)\n",
        "  probabilities = probabilities.iloc[:,3:]\n",
        "  n_array = probabilities.values\n",
        "  columns = list(probabilities.columns)[1:]\n",
        "\n",
        "  expressions = ['disgust','surprise','anger','happiness','sadness','fear']\n",
        "  primary_aus = {'disgust':[9,10],'surprise':[1,2,5,25,26],'anger':[4,5,23,24],'happiness':[6,12],'sadness':[1,7,15],'fear':[1,2,4,5,7,20]}\n",
        "  secondary_aus = {'disgust':[17,25],'surprise':[16],'anger':[7,17],'happiness':[7,25],'sadness':[4,6,17],'fear':[23,25]}\n",
        "  nested_dict = lambda: defaultdict(nested_dict)\n",
        "  master_aus_prob = nested_dict()\n",
        "  for i in expressions:\n",
        "      temp_expr = probabilities[(probabilities['Expressions']==i)]\n",
        "      temp_aus = temp_expr.iloc[:,1:].values\n",
        "      for j in columns:\n",
        "          index_au = columns.index(j)\n",
        "          master_aus_prob[i][j] = np.sum(temp_aus[:,index_au],axis=0)/float(temp_aus.shape[0])\n",
        "  return master_aus_prob[emotion][au]\n",
        "\n",
        "#Get expression dependent joint AU probability that is calculated from dataset\n",
        "def get_prob_ij_under_k(au_pair, emotion):\n",
        "  dataset = pd.ExcelFile('/content/Probabilities.xlsx')\n",
        "  probabilities = dataset.parse(0)\n",
        "  probabilities_expressions = probabilities.iloc[:,3:]\n",
        "  n_array = probabilities.values\n",
        "  n_array_expr = probabilities_expressions.values\n",
        "  columns = list(probabilities.columns)[4:]\n",
        "\n",
        "  #dependent_aus = {'anger':[(4,5),(4,7),(4,5,7),(17,24),(23,)],'disgust':[(9,),(10,)],'fear':[(1,2,4),(20,)],'happiness':[(12,),(6,12),(7,12)],'sadness':[(1,),(1,4),(15,),(6,15)],'surprise':[(1,2,5),(1,2,26),(1,2,5,26)]}\n",
        "  dependent_aus = {'anger':[(4,5),(4,7),(17,24)],'disgust':[],'fear':[(1,2), (1,4), (2,4)],'happiness':[(6,12),(7,12)],'sadness':[(1,4), (6,15)],'surprise':[(1,2), (1,5), (2,5), (2,26), (1,26), (1,5), (5,26)]}\n",
        "  nested_dict = lambda: defaultdict(nested_dict)\n",
        "  dependent_aus_prob = nested_dict()\n",
        "  for i in dependent_aus:\n",
        "      temp_expr = probabilities_expressions[(probabilities_expressions['Expressions']==i)]\n",
        "      temp_aus = temp_expr.iloc[:,1:].values\n",
        "      for j in dependent_aus[i]:\n",
        "          j1 = [columns.index(x) for x in j]\n",
        "          temp = temp_aus[:,j1]\n",
        "          dependent_aus_prob[i][j] = temp.tolist().count([1]*temp.shape[1])/float(temp_aus.shape[0])\n",
        "  return dependent_aus_prob[emotion][au_pair]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3_dZRXaAbiUI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "5baec577-337e-46d6-969a-f884078920d9"
      },
      "cell_type": "code",
      "source": [
        "#AU list considered in our solution derived from table2 - 17 AUs\n",
        "# au_list = [1,2,4,5,6,7,9,10,12,15,16,17,20,23,24,25,26,27]\n",
        "#au_list = [1,2,4,5,6,7,9,12,15,17,20,23,24,26]\n",
        "#au_list = [1,2,4,6,7,9,12,15,17,23,24]\n",
        "# au_list = [1,2,4,6,7]\n",
        "emotion_list = [\"anger\",\"disgust\",\"fear\",\"happiness\",\"sadness\",\"surprise\"]\n",
        "primary_au = {\n",
        "              \"anger\": [4,5,23,24],\n",
        "              \"disgust\": [9,10],\n",
        "              \"fear\": [1,2,4,5,7,20],\n",
        "              \"happiness\": [6,12],\n",
        "              \"sadness\": [1,7,15],\n",
        "              \"surprise\": [1,2,5,25,26]\n",
        "              }\n",
        "secondary_au = {\n",
        "              \"anger\": [7,17],\n",
        "              \"disgust\": [17,25],\n",
        "              \"fear\": [23,25],\n",
        "              \"happiness\": [7,25],\n",
        "              \"sadness\": [4,6,17],\n",
        "              \"surprise\": [16]\n",
        "}\n",
        "others_au = {\n",
        "              \"anger\": [1, 2, 6, 9, 10, 12, 15, 16, 20, 25, 26],\n",
        "              \"disgust\": [1, 2, 4, 5, 6, 7, 12, 15, 16, 20, 23, 24, 26],\n",
        "              \"fear\": [6, 9, 10, 12, 15, 16, 17, 24, 26],\n",
        "              \"happiness\": [1, 2, 4, 5, 9, 10, 15, 16, 17, 20, 23, 24, 26],\n",
        "              \"sadness\": [2, 5, 9, 10, 12, 16, 20, 23, 24, 25, 26],\n",
        "              \"surprise\": [4, 6, 7, 9, 10, 12, 15, 17, 20, 23, 24]\n",
        "}\n",
        "\n",
        "#Expression independent FACS encoded AU pairs\n",
        "positive_au_pairs = [(1,2), (4,7) , (4,9), (7,9), (6,12), (9,17), (15,17), (15,24), (17,24), (23,24)]\n",
        "negative_au_pairs = [(2,6), (2,7), (12,15), (12,17)]\n",
        "\n",
        "#derived from emfacs table4 - pairing two-wise\n",
        "emfacs_pairs = {\n",
        "          \"anger\": [(4,5), (4,7), (17,24)],\n",
        "          \"disgust\": [],\n",
        "          \"fear\": [(1,2), (1,4), (2,4)],\n",
        "          \"happiness\": [(6,12), (7,12)],\n",
        "          \"sadness\": [(1,4), (6,15)],\n",
        "          \"surprise\": [(1,2), (1,5), (2,5), (2,26), (1,26), (1,5), (5,26)]\n",
        "}\n",
        "\n",
        "#generate list of test AU configs\n",
        "au_test_config_arr = np.array(list(itertools.product([0, 1], repeat=len(au_list))))\n",
        "print(au_test_config_arr.shape)\n",
        "s = np.sum(au_test_config_arr,1)\n",
        "del_list=[]\n",
        "for x in range(s.shape[0]):\n",
        "  if s[x] <= 1:\n",
        "    del_list.append(x)\n",
        "print(del_list)\n",
        "au_test_config_arr = np.delete(au_test_config_arr, del_list, 0)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8, 3)\n",
            "[0, 1, 2, 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DEOyviZTMYQ_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4043
        },
        "outputId": "9af9b612-48c5-4160-bd33-8772a3738f5b"
      },
      "cell_type": "code",
      "source": [
        "#Complete code - run from here\n",
        "main_obj = min_obj = 100000\n",
        "au_list = [1,2,4,5,6,7,9,10,12,15,16,17,20,23,24,25,26,27]\n",
        "# au_list = [1,2,4]\n",
        "\n",
        "def init_y():\n",
        "  #Initialize y from table2\n",
        "  y_new = np.ndarray(shape=(269, len(au_list)), dtype=np.int)\n",
        "  dataset = pd.ExcelFile('/content/Probabilities.xlsx')\n",
        "  probabilities = dataset.parse(0)\n",
        "  temp = probabilities.iloc[:,[4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21]]\n",
        "  #temp = probabilities.iloc[:,[4,5,6]]\n",
        "  y_new = temp.values\n",
        "  return y_new\n",
        "\n",
        "def core_algo(y_new, au_list, min_obj):\n",
        "  \n",
        "  #step1 train linear SVM: fix Y, optimize W\n",
        "  W, X, x_expr = eq21_training(y_new, au_list)\n",
        "  \n",
        "  #step2 greedy algo: fix W, optimize Y\n",
        "  for i in range(X.shape[0]):\n",
        "    x=X[i]\n",
        "    x_expr_label = x_expr[i]\n",
        "    #step4 find best AU config for a sample (tried parallelize but causing issue in numpy array)\n",
        "    y_temp = get_eq22_best_AU_config(au_test_config_arr, x, i, x_expr_label, W, au_list, primary_au, secondary_au, others_au, positive_au_pairs, negative_au_pairs, emotion_list)\n",
        "    print('eq22_config for sample{} is {}'.format(i,y_temp))\n",
        "    #compute eq20_obj for above sample\n",
        "    x_obj = compute_eq20_obj(y_temp, X, W, x_expr_label, y_new[0:269,:], au_list, primary_au, secondary_au, others_au, positive_au_pairs, negative_au_pairs, emotion_list)\n",
        "    print('min_eq20_obj before sample{} is {}'.format(i,min_obj))\n",
        "    print('eq20_obj for sample{} is {}'.format(i,x_obj))\n",
        "    if x_obj < min_obj:\n",
        "      min_obj = x_obj\n",
        "      y_new[i] = y_temp          #replace y[i]\n",
        "\n",
        "  return y_new, min_obj\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  y_new = init_y()\n",
        "  y_new, main_obj = core_algo(y_new, au_list, main_obj)\n",
        "  while (main_obj - min_obj) > 0.001:\n",
        "      y_new, min_obj = core_algo(y_new, au_list, min_obj)\n",
        "      print(main_obj, min_obj)\n",
        "      if min_obj < main_obj:\n",
        "        main_obj = min_obj\n",
        "        min_obj = 0"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2.35811395e-05 2.35811395e-05 2.35811395e-05 ... 2.35811395e-05\n",
            "  2.35811395e-05 2.35811395e-05]]\n",
            "[2.35811395e-05 2.35811395e-05 2.35811395e-05 ... 2.35811395e-05\n",
            " 2.35811395e-05 2.35811395e-05]\n",
            "*************AU1 Classifier*************\n",
            "Pred: [1 0 1 1 1 0 0 1 1 1 1 0 1 1 0 0 1 0 1 1 0 0 0 1 0 1 0 0 1 0 1 0 0 1 1 0 1\n",
            " 0 0]\n",
            "Test: [1 0 0 1 0 1 0 0 0 0 1 0 1 1 0 0 1 1 0 1 1 0 1 0 1 1 0 1 0 1 0 1 1 1 0 1 1\n",
            " 0 1]\n",
            "AU1 classifier co-eficients: (1, 10201)\n",
            "Classification report for classifier LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
            "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
            "     multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,\n",
            "     verbose=0),              precision    recall  f1-score   support\n",
            "\n",
            "          0       0.42      0.44      0.43        18\n",
            "          1       0.50      0.48      0.49        21\n",
            "\n",
            "avg / total       0.46      0.46      0.46        39\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 8 10]\n",
            " [11 10]]\n",
            "71.9481480122\n",
            "[[1.03966904e-05 1.03966904e-05 1.03966904e-05 ... 1.03966904e-05\n",
            "  1.03966904e-05 1.03966904e-05]]\n",
            "[1.03966904e-05 1.03966904e-05 1.03966904e-05 ... 1.03966904e-05\n",
            " 1.03966904e-05 1.03966904e-05]\n",
            "*************AU2 Classifier*************\n",
            "Pred: [0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
            " 0 0]\n",
            "Test: [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0\n",
            " 0 1]\n",
            "AU2 classifier co-eficients: (1, 10201)\n",
            "Classification report for classifier LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
            "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
            "     multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,\n",
            "     verbose=0),              precision    recall  f1-score   support\n",
            "\n",
            "          0       0.81      0.91      0.85        32\n",
            "          1       0.00      0.00      0.00         7\n",
            "\n",
            "avg / total       0.66      0.74      0.70        39\n",
            "\n",
            "Confusion matrix:\n",
            "[[29  3]\n",
            " [ 7  0]]\n",
            "70.8632810116\n",
            "[[-9.37588619e-06 -9.37588619e-06 -9.37588619e-06 ... -9.37588619e-06\n",
            "  -9.37588619e-06 -9.37588619e-06]]\n",
            "[-9.37588619e-06 -9.37588619e-06 -9.37588619e-06 ... -9.37588619e-06\n",
            " -9.37588619e-06 -9.37588619e-06]\n",
            "*************AU4 Classifier*************\n",
            "Pred: [0 1 1 0 1 0 0 0 1 1 1 0 1 0 1 1 1 1 1 1 0 1 0 0 0 0 0 0 1 0 1 0 0 1 1 1 1\n",
            " 1 1]\n",
            "Test: [1 0 0 1 1 1 0 1 0 0 1 0 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1]\n",
            "AU4 classifier co-eficients: (1, 10201)\n",
            "Classification report for classifier LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
            "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
            "     multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,\n",
            "     verbose=0),              precision    recall  f1-score   support\n",
            "\n",
            "          0       0.12      0.22      0.15         9\n",
            "          1       0.68      0.50      0.58        30\n",
            "\n",
            "avg / total       0.55      0.44      0.48        39\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 2  7]\n",
            " [15 15]]\n",
            "72.6308169365\n",
            "clf_loss:5.04078762979 eq8_loss:6.95908086426 eq11_loss:24.6987951807 eq13_loss:0 eq15_loss:4.63213629336 eq19_loss:6.20269923962\n",
            "sample: 0 x_loss: 15.8444997359 for [0 1 1] min_loss: 15.8444997359 for [0 1 1] under 5.84166693687s\n",
            "clf_loss:4.99639451317 eq8_loss:6.95908086426 eq11_loss:43.3734939759 eq13_loss:0 eq15_loss:4.63213629336 eq19_loss:3.16285485001\n",
            "sample: 0 x_loss: 21.0413201656 for [1 0 1] min_loss: 15.8444997359 for [0 1 1] under 5.30141806602s\n",
            "clf_loss:5.02603711722 eq8_loss:0 eq11_loss:24.6987951807 eq13_loss:0 eq15_loss:0 eq19_loss:7.65546697634\n",
            "sample: 0 x_loss: 12.4600997581 for [1 1 0] min_loss: 12.4600997581 for [1 1 0] under 4.84923291206s\n",
            "clf_loss:6.03160963009 eq8_loss:4.92317843341 eq11_loss:24.6987951807 eq13_loss:0 eq15_loss:4.63213629336 eq19_loss:7.14623240844\n",
            "sample: 0 x_loss: 15.8106506487 for [1 1 1] min_loss: 12.4600997581 for [1 1 0] under 5.98614120483s\n",
            "eq22_config for sample0 is [1 1 0]\n",
            "min_eq20_obj before sample0 is 100000\n",
            "eq20_obj for sample0 is 11.7847540524\n",
            "clf_loss:2.9915425937 eq8_loss:6.95908086426 eq11_loss:0.724637681159 eq13_loss:0 eq15_loss:4.63213629336 eq19_loss:6.20269923962\n",
            "sample: 1 x_loss: 7.17003222403 for [0 1 1] min_loss: 7.17003222403 for [0 1 1] under 5.67222285271s\n",
            "clf_loss:2.98931246857 eq8_loss:6.95908086426 eq11_loss:0.724637681159 eq13_loss:0 eq15_loss:4.63213629336 eq19_loss:3.16285485001\n",
            "sample: 1 x_loss: 6.15600738579 for [1 0 1] min_loss: 6.15600738579 for [1 0 1] under 5.18259000778s\n",
            "clf_loss:1.00223012513 eq8_loss:0 eq11_loss:0.724637681159 eq13_loss:0 eq15_loss:0 eq19_loss:7.65546697634\n",
            "sample: 1 x_loss: 3.12744492754 for [1 1 0] min_loss: 3.12744492754 for [1 1 0] under 4.8095741272s\n",
            "clf_loss:1.9915425937 eq8_loss:4.92317843341 eq11_loss:0.724637681159 eq13_loss:0 eq15_loss:4.63213629336 eq19_loss:7.14623240844\n",
            "sample: 1 x_loss: 6.47257580335 for [1 1 1] min_loss: 3.12744492754 for [1 1 0] under 6.12334990501s\n",
            "eq22_config for sample1 is [1 1 0]\n",
            "min_eq20_obj before sample1 is 11.7847540524\n",
            "eq20_obj for sample1 is 3.79336821917\n",
            "clf_loss:3.04528071882 eq8_loss:6.95908086426 eq11_loss:5.55555555556 eq13_loss:0 eq15_loss:4.63213629336 eq19_loss:6.20269923962\n",
            "sample: 2 x_loss: 8.79825089054 for [0 1 1] min_loss: 8.79825089054 for [0 1 1] under 5.76274800301s\n",
            "clf_loss:2.98896347121 eq8_loss:6.95908086426 eq11_loss:5.55555555556 eq13_loss:0 eq15_loss:4.63213629336 eq19_loss:3.16285485001\n",
            "sample: 2 x_loss: 7.76619701146 for [1 0 1] min_loss: 7.76619701146 for [1 0 1] under 5.18283510208s\n",
            "clf_loss:5.03424419004 eq8_loss:0 eq11_loss:5.55555555556 eq13_loss:0 eq15_loss:0 eq19_loss:7.65546697634\n",
            "sample: 2 x_loss: 6.08175557398 for [1 1 0] min_loss: 6.08175557398 for [1 1 0] under 4.98904585838s\n",
            "clf_loss:4.03424419004 eq8_loss:4.92317843341 eq11_loss:5.55555555556 eq13_loss:0 eq15_loss:4.63213629336 eq19_loss:7.14623240844\n",
            "sample: 2 x_loss: 8.7637822936 for [1 1 1] min_loss: 6.08175557398 for [1 1 0] under 6.12991786003s\n",
            "eq22_config for sample2 is [1 1 0]\n",
            "min_eq20_obj before sample2 is 3.79336821917\n",
            "eq20_obj for sample2 is 5.4036741773\n",
            "clf_loss:5.45600131515 eq8_loss:6.95908086426 eq11_loss:24.6987951807 eq13_loss:0 eq15_loss:4.63213629336 eq19_loss:6.20269923962\n",
            "sample: 3 x_loss: 15.9829042977 for [0 1 1] min_loss: 15.9829042977 for [0 1 1] under 5.81154799461s\n",
            "clf_loss:5.75683431421 eq8_loss:6.95908086426 eq11_loss:43.3734939759 eq13_loss:0 eq15_loss:4.63213629336 eq19_loss:3.16285485001\n",
            "sample: 3 x_loss: 21.2948000992 for [1 0 1] min_loss: 15.9829042977 for [0 1 1] under 5.30384588242s\n",
            "clf_loss:6.18511422507 eq8_loss:0 eq11_loss:24.6987951807 eq13_loss:0 eq15_loss:0 eq19_loss:7.65546697634\n",
            "sample: 3 x_loss: 12.846458794 for [1 1 0] min_loss: 12.846458794 for [1 1 0] under 4.80101299286s\n",
            "clf_loss:7.19897492721 eq8_loss:4.92317843341 eq11_loss:24.6987951807 eq13_loss:0 eq15_loss:4.63213629336 eq19_loss:7.14623240844\n",
            "sample: 3 x_loss: 16.1997724144 for [1 1 1] min_loss: 12.846458794 for [1 1 0] under 6.25696086884s\n",
            "eq22_config for sample3 is [1 1 0]\n",
            "min_eq20_obj before sample3 is 3.79336821917\n",
            "eq20_obj for sample3 is 11.7847540524\n",
            "clf_loss:3.01214062129 eq8_loss:6.95908086426 eq11_loss:5.55555555556 eq13_loss:0 eq15_loss:4.63213629336 eq19_loss:6.20269923962\n",
            "sample: 4 x_loss: 8.78720419136 for [0 1 1] min_loss: 8.78720419136 for [0 1 1] under 5.81957101822s\n",
            "clf_loss:3.01214062129 eq8_loss:6.95908086426 eq11_loss:5.55555555556 eq13_loss:0 eq15_loss:4.63213629336 eq19_loss:3.16285485001\n",
            "sample: 4 x_loss: 7.77392272816 for [1 0 1] min_loss: 7.77392272816 for [1 0 1] under 5.20325684547s\n",
            "clf_loss:1.0 eq8_loss:0 eq11_loss:5.55555555556 eq13_loss:0 eq15_loss:0 eq19_loss:7.65546697634\n",
            "sample: 4 x_loss: 4.73700751063 for [1 1 0] min_loss: 4.73700751063 for [1 1 0] under 5.00261688232s\n",
            "clf_loss:2.01214062129 eq8_loss:4.92317843341 eq11_loss:5.55555555556 eq13_loss:0 eq15_loss:4.63213629336 eq19_loss:7.14623240844\n",
            "sample: 4 x_loss: 8.08974777068 for [1 1 1] min_loss: 4.73700751063 for [1 1 0] under 6.15489411354s\n",
            "eq22_config for sample4 is [1 1 0]\n",
            "min_eq20_obj before sample4 is 3.79336821917\n",
            "eq20_obj for sample4 is 5.4036741773\n",
            "clf_loss:3.02555400401 eq8_loss:6.95908086426 eq11_loss:0.724637681159 eq13_loss:0 eq15_loss:4.63213629336 eq19_loss:6.20269923962\n",
            "sample: 5 x_loss: 7.1813693608 for [0 1 1] min_loss: 7.1813693608 for [0 1 1] under 5.69790101051s\n",
            "clf_loss:1.0 eq8_loss:6.95908086426 eq11_loss:0.724637681159 eq13_loss:0 eq15_loss:4.63213629336 eq19_loss:3.16285485001\n",
            "sample: 5 x_loss: 5.49290322959 for [1 0 1] min_loss: 5.49290322959 for [1 0 1] under 5.23506402969s\n",
            "clf_loss:3.02555400401 eq8_loss:0 eq11_loss:0.724637681159 eq13_loss:0 eq15_loss:0 eq19_loss:7.65546697634\n",
            "sample: 5 x_loss: 3.8018862205 for [1 1 0] min_loss: 3.8018862205 for [1 1 0] under 4.793405056s\n",
            "clf_loss:2.02555400401 eq8_loss:4.92317843341 eq11_loss:0.724637681159 eq13_loss:0 eq15_loss:4.63213629336 eq19_loss:7.14623240844\n",
            "sample: 5 x_loss: 6.48391294012 for [1 1 1] min_loss: 3.8018862205 for [1 1 0] under 6.13646292686s\n",
            "eq22_config for sample5 is [1 1 0]\n",
            "min_eq20_obj before sample5 is 3.79336821917\n",
            "eq20_obj for sample5 is 3.79336821917\n",
            "clf_loss:2.99647284231 eq8_loss:6.95908086426 eq11_loss:0 eq13_loss:0 eq15_loss:4.63213629336 eq19_loss:6.20269923962\n",
            "sample: 6 x_loss: 6.93012974651 for [0 1 1] min_loss: 6.93012974651 for [0 1 1] under 5.71350312233s\n",
            "clf_loss:1.0 eq8_loss:6.95908086426 eq11_loss:6.0 eq13_loss:0 eq15_loss:4.63213629336 eq19_loss:3.16285485001\n",
            "sample: 6 x_loss: 7.25135733587 for [1 0 1] min_loss: 6.93012974651 for [0 1 1] under 5.20595383644s\n",
            "clf_loss:2.99647284231 eq8_loss:0 eq11_loss:0 eq13_loss:0 eq15_loss:0 eq19_loss:7.65546697634\n",
            "sample: 6 x_loss: 3.55064660622 for [1 1 0] min_loss: 3.55064660622 for [1 1 0] under 4.84355306625s\n",
            "clf_loss:1.99647284231 eq8_loss:4.92317843341 eq11_loss:0 eq13_loss:0 eq15_loss:4.63213629336 eq19_loss:7.14623240844\n",
            "sample: 6 x_loss: 6.23267332584 for [1 1 1] min_loss: 3.55064660622 for [1 1 0] under 6.00664496422s\n",
            "eq22_config for sample6 is [1 1 0]\n",
            "min_eq20_obj before sample6 is 3.79336821917\n",
            "eq20_obj for sample6 is 3.55182232545\n",
            "clf_loss:3.00545985452 eq8_loss:6.95908086426 eq11_loss:24.6987951807 eq13_loss:0 eq15_loss:4.63213629336 eq19_loss:6.20269923962\n",
            "sample: 7 x_loss: 15.1660571442 for [0 1 1] min_loss: 15.1660571442 for [0 1 1] under 5.74592089653s\n",
            "clf_loss:2.9961241924 eq8_loss:6.95908086426 eq11_loss:43.3734939759 eq13_loss:0 eq15_loss:4.63213629336 eq19_loss:3.16285485001\n",
            "sample: 7 x_loss: 20.374563392 for [1 0 1] min_loss: 15.1660571442 for [0 1 1] under 5.27665495872s\n",
            "clf_loss:4.99506513493 eq8_loss:0 eq11_loss:24.6987951807 eq13_loss:0 eq15_loss:0 eq19_loss:7.65546697634\n",
            "sample: 7 x_loss: 12.449775764 for [1 1 0] min_loss: 12.449775764 for [1 1 0] under 4.74592208862s\n",
            "clf_loss:3.99832459092 eq8_loss:4.92317843341 eq11_loss:24.6987951807 eq13_loss:0 eq15_loss:4.63213629336 eq19_loss:7.14623240844\n",
            "sample: 7 x_loss: 15.1328889689 for [1 1 1] min_loss: 12.449775764 for [1 1 0] under 6.04616689682s\n",
            "eq22_config for sample7 is [1 1 0]\n",
            "min_eq20_obj before sample7 is 3.55182232545\n",
            "eq20_obj for sample7 is 11.7847540524\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-4f512633242c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0my_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0my_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmain_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcore_algo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mau_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmain_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmain_obj\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmin_obj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m       \u001b[0my_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcore_algo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mau_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-50-4f512633242c>\u001b[0m in \u001b[0;36mcore_algo\u001b[0;34m(y_new, au_list, min_obj)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mx_expr_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_expr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m#step4 find best AU config for a sample (tried parallelize but causing issue in numpy array)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0my_temp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_eq22_best_AU_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mau_test_config_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_expr_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mau_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimary_au\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msecondary_au\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mothers_au\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositive_au_pairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_au_pairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memotion_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'eq22_config for sample{} is {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_temp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m#compute eq20_obj for above sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-36-5d35a5a98acf>\u001b[0m in \u001b[0;36mget_eq22_best_AU_config\u001b[0;34m(au_test_config_arr, x, sample_no, x_expr_label, W, au_list, primary_au, secondary_au, others_au, positive_au_pairs, negative_au_pairs, emotion_list)\u001b[0m\n\u001b[1;32m    154\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mtest_au_config\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mau_test_config_arr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0mtick\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m     \u001b[0mx_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meq22_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_au_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_expr_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mau_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimary_au\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msecondary_au\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mothers_au\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositive_au_pairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_au_pairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memotion_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmin_loss\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m       \u001b[0mmin_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-36-5d35a5a98acf>\u001b[0m in \u001b[0;36meq22_loss\u001b[0;34m(test_au_config, x, W, x_expr_label, au_list, primary_au, secondary_au, others_au, positive_au_pairs, negative_au_pairs, emotion_list)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m   \u001b[0;31m#Loss_eq8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m   \u001b[0mLoss_eq8\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlambd_eq8\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0meq8_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_au_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositive_au_pairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_au_pairs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0;31m#Loss_eq11\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-36-5d35a5a98acf>\u001b[0m in \u001b[0;36meq8_loss\u001b[0;34m(test_au_labels, positive_au_pairs, negative_au_pairs)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mprob_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_prob_i\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpt_pair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mprob_j\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_prob_i\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpt_pair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mprob_ij\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_prob_ij\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpt_pair\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mpt_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob_i\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mprob_j\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mprob_ij\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mprob_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mprob_j\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mprob_ij\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob_i\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mprob_j\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mprob_ij\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-5f2103ab5c86>\u001b[0m in \u001b[0;36mget_prob_ij\u001b[0;34m(au_pair)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m#Get expression independent marginal AU probability that is calculated from dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_prob_ij\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mau_pair\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m   \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExcelFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/Probabilities.xlsx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m   \u001b[0mprobabilities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m   \u001b[0mprobabilities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprobabilities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pandas/io/excel.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, io, **kwds)\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxlrd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_contents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxlrd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             raise ValueError('Must explicitly set engine if not passing in'\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/xlrd/__init__.pyc\u001b[0m in \u001b[0;36mopen_workbook\u001b[0;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows)\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mformatting_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformatting_info\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                 \u001b[0mon_demand\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon_demand\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m                 \u001b[0mragged_rows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mragged_rows\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m                 )\n\u001b[1;32m    145\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mbk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/xlrd/xlsx.pyc\u001b[0m in \u001b[0;36mopen_workbook_2007_xml\u001b[0;34m(zf, component_names, logfile, verbosity, use_mmap, formatting_info, on_demand, ragged_rows)\u001b[0m\n\u001b[1;32m    835\u001b[0m         \u001b[0mx12sheet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX12Sheet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msheet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbosity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m         \u001b[0mheading\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Sheet %r (sheetx=%d) from %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msheet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msheetx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 837\u001b[0;31m         \u001b[0mx12sheet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzflo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheading\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    838\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mzflo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/xlrd/xlsx.pyc\u001b[0m in \u001b[0;36mown_process_stream\u001b[0;34m(self, stream, heading)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mU_SSML12\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"dimension\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_dimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m             \u001b[0;32melif\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mU_SSML12\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"mergeCell\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_merge_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinish_off\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}